{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQYV0kQbV4ka"
   },
   "source": [
    "# Worked Example 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrcRBhREV4kb"
   },
   "source": [
    "In this exercise, you will practice selecting and transforming data using the `numpy` and `pandas` Python libraries. You can search on the web for documentation and techniques to help you solve the problem. See especially the official [Numpy documentation](https://numpy.org/doc/stable/) and [Pandas documentation](https://pandas.pydata.org/docs/user_guide/index.html).\n",
    "\n",
    "For every sub-question under every Question, please save results in corresponding variables. For instance, results of Question 1 should be saved in variables named `q1_1`, `q1_2`, ... , `q1_10`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Homeworks, the autograders for worked examples are embedded with the questions so that you can run the tests yourself. Read the instructions below carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograder Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to install the `Otter` autograder package the first time it is run. Afterwards, running it again will print out its version number if `Otter` is correctly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import otter\n",
    "    grader = otter.Notebook(\"worked-example02.ipynb\")\n",
    "    print(otter.__version__)\n",
    "    if (otter.__version__ != '6.1.6'): #update for latest otter version\n",
    "        !pip install -q -U --user otter-grader\n",
    "except Exception as e:\n",
    "    !pip install -q otter-grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To grade your own work, simply run the cell starting with `grader.check` immediately after each question. The cell calls `Otter` to run the tests for all subquestions and generate a report of what test(s) you pass/do not pass in the same style as on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ayL0i19V4kb"
   },
   "source": [
    "## Part 1: Numpy\n",
    "In this part you will practice with the functions and conventions of the `numpy` library using `numpy` arrays. You may find it helpful to start by looking at the official `numpy` Quickstart [tutorial](https://numpy.org/doc/stable/user/quickstart.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6aqL8XfV4kc"
   },
   "outputs": [],
   "source": [
    "# Run this code cell to import the NumPy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLGdAvkdV4kd"
   },
   "source": [
    "### Question 1\n",
    "This question provides some exercise for basic indexing, slicing, and aggregating functions in `numpy`. The code below generates a 10 by 10 `numpy` array of random integers between 0 and 100 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c5FnHR3V4ke"
   },
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "np.random.seed(0) # so you get the same results each time\n",
    "vals = np.random.randint(0, 100, (10,10)) # from 0 to 100, shape 10 by 10\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnN0a7wGV4kf"
   },
   "source": [
    "Without writing any loops, write code to answer the following questions where question 1's answer is in the variable `q1_1`, question 2's answer is in `q1_2`, and so on.\n",
    "\n",
    "1. The value at row index 2 and column index 1.\n",
    "2. The last value in the first row.\n",
    "3. The largest value overall.  \n",
    "4. All of the values in the first column.\n",
    "5. The mean of the values in the first row.\n",
    "6. The minimum of the values in the last column.\n",
    "7. The mean of the values in the first 5 rows and the first five columns.\n",
    "8. The five smallest values in the first row, in order from least to greatest.\n",
    "9. The minimum value of every row.\n",
    "10. The index of the column with the largest mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDbmtUspV4kg",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code to answer Question 1 here\n",
    "q1_1 = ...\n",
    "q1_2 = ...\n",
    "q1_3 = ...\n",
    "q1_4 = ...\n",
    "q1_5 = ...\n",
    "q1_6 = ...\n",
    "q1_7 = ...\n",
    "q1_8 = ...\n",
    "q1_9 = ...\n",
    "q1_10 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODEsDJGIV4kk"
   },
   "source": [
    "### Question 2\n",
    "This question provides some exercise for fast element-wise computation with `numpy` ufuncs. The code below generates a random 2d `numpy` array `points` that contains 5 points, each of which has an x-value and a y-value. Each row corresponds to a point, the first column (column index 0) contains the x-value, and the second column (column index 1) contains the y-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6hfpU7-V4kk"
   },
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "np.random.seed(0) # so you get the same results each time\n",
    "points = np.random.randn(5, 2) # draws values from standard normal distribution\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSu8DmUgV4kl"
   },
   "source": [
    "Without writing any loops, write code answer the following questions where quesiton 1's answer is in the variables `q2_1`, question 2's is in `q2_2`, and so on.\n",
    "\n",
    "1. Two times every value in `points`.\n",
    "2. The square of every x-value.\n",
    "3. The 0-centered y-values: Subtract the mean over all y-values from every y-value.\n",
    "4. The mean of the *positive* values in `points`.\n",
    "5. The points with x-values greater than their y-values.\n",
    "6. The magnitude of the first point. The magnitude of a point $(x, y)$ is it's Euclidean distance from the origin equal to $\\sqrt{x^2 + y^2}$. \n",
    "7. The Euclidean distance between the first and the second point. The Euclidean distance formula between two points $(x_1, y_1)$ and $(x_2, y_2)$ is $\\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}$.\n",
    "8. The Euclidean distance between the first point and all points (you may include the distance of 0 from the first point to itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4oWRzr3V4kl",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code to answer Question 2 here\n",
    "q2_1 = ...\n",
    "q2_2 = ...\n",
    "q2_3 = ...\n",
    "q2_4 = ...\n",
    "q2_5 = ...\n",
    "q2_6 = ...\n",
    "q2_7 = ...\n",
    "q2_8 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coqGyQ36V4kn"
   },
   "source": [
    "## Part 2: Pandas\n",
    "In this part you will practice manipulating `pandas` Series and Dataframes. You may find it helpful to start by looking at the *10 minutes to pandas* [tutorial](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KG02lBM6V4kn"
   },
   "outputs": [],
   "source": [
    "# Run this code cell to import the Pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nCAxGYuV4ko"
   },
   "source": [
    "### Question 3\n",
    "The dataset `temp` imported below as a `pandas` series shows temperature deviations (in Celsius) relative to the 1951-1980 mean, courtesy of [NASA](https://climate.nasa.gov/vital-signs/global-temperature/). Note the row labels are integers (years)! Therefore, think carefully about whether an int between the square brackets is being treated as a row label or an index. \n",
    "\n",
    "Hint: `.loc` slices by row label while `.iloc` slices by row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0urMvA3xV4ko"
   },
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "temp = pd.read_csv(\"climate.csv\", index_col=0).squeeze(\"columns\")\n",
    "print(temp.head())\n",
    "temp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inMjtAlnV4ko"
   },
   "source": [
    "Without writing any loops, write code to answer the following questions where answers are in the variables `q3_1`, `q3_2`, and so on.\n",
    "\n",
    "1. The temperature deviation in 1900?\n",
    "2. Temperature deviations for the last three years (most recent) for which there is data\n",
    "3. Temperature deviations for the last three years (most recent) for which there is data converted to Fahrenheit (temperature deviation in Fahrenheit is just 1.8 times the Celsius).\n",
    "4. The mean temperature deviation since 1990 (including 1990). Remember the difference between row labels and index.\n",
    "5. The number of years with positive temperature deviations.\n",
    "6. The number of those years with positive temperature deviations taking place since 1970 (including 1970).\n",
    "7. The five hottest years on record in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c2tNZfgV4ko",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code to answer Question 3 here\n",
    "q3_1 = ...\n",
    "q3_2 = ...\n",
    "q3_3 = ...\n",
    "q3_4 = ...\n",
    "q3_5 = ...\n",
    "q3_6 = ...\n",
    "q3_7 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zb1W_9EV4kp"
   },
   "source": [
    "### Question 4\n",
    "The dataset `df` imported below as a `pandas` dataframe shows statistics about nations and the happiness of citizens from the United Nations [World Happiness Report](https://worldhappiness.report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdSXxiauV4kp"
   },
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "df = pd.read_csv(\"happiness.csv\", index_col = \"Country name\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI2mnq1oV4kp"
   },
   "source": [
    "Without writing any loops, write code to answer the following questions answers are in the variables `q4_1`, `q4_2`, and so on.\n",
    "\n",
    "1. All of the data corresponding to the country name `United States`. \n",
    "2. All of the data corresponding to the country at row index 50.\n",
    "3. The mean happiness score.\n",
    "4. The number of countries with `Happiness` scores greater than 6.\n",
    "5. The number of countries with `Log GDP per capita` less than 9.\n",
    "6. The number of countries with `Happiness` scores greater than 6 and Log GDP per capita less than 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1OsY94JhV4kq",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code to answer Question 4 here\n",
    "q4_1 = ...\n",
    "q4_2 = ...\n",
    "q4_3 = ...\n",
    "q4_4 = ...\n",
    "q4_5 = ...\n",
    "q4_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (Open-ended question practice)\n",
    "\n",
    "Having now explored the data in various ways, in this question, you should analyze the data yourself by designing your own statistic. It can be an integer or float but should be a single number (as opposed to a number per state). Put the result of your analysis in the variable `statistic`. Then, explain your statistic in the written part of this question. Be precise in what you did. What data did you use? What did you not use? What kind of statistic is it? What does that value tell you about the data?\n",
    "\n",
    "**Grading of this question**: It will be graded using an ESNU rubric as follows:\n",
    "- Exemplary - Work that meets all requirements and displays full mastery of all learning goals for this question. And the code and write-up are clean and easy to understand.\n",
    "- Satisfactory - Work that meets all requirements and displays at least partial mastery of all learning goals as well as full mastery of core learning goals. In other words, it is not an E, but it fulfills the requirements, including (but not necessarily only) the code matches what the write-up claims it is.\n",
    "- Not Yet - Work that does not meet some requirements and/or displays developing or incomplete mastery of at least some learning goals. For example, the code and write-up do not match, or the write-up states something incorrectly.\n",
    "- Unasessable - Work that is missing, does not demonstrate meaningful effort, or does not provide enough evidence to determine a level of mastery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "statistic = temp.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Answer 5: Written portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practice2a_ksm_fixed.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(q1_1 == 37)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q1_2 == 87)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q1_3 == 99)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q1_4 == [44, 70, 81, 47, 39, 75, 17, 35, 42, 78]\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import math\n>>> math.isclose(q1_5, 52.5, abs_tol=0.01)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q1_6 == 12)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import math\n>>> math.isclose(q1_7, 59.16, abs_tol=0.01)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q1_8 == [9, 21, 36, 44, 47]\narray([ True,  True,  True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q1_9 == [9, 12, 9, 14, 9, 0, 1, 0, 3, 13]\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q1_10 == 3)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.allclose(q2_1, [[3.52810469, 0.80031442], [1.95747597, 4.4817864], [3.73511598, -1.95455576], [1.90017684, -0.30271442], [-0.2064377, 0.821197]], atol=1e-05)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(q2_2, [3.11188068, 0.95792804, 3.48777285, 0.902668, 0.01065413], atol=1e-05)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(q2_3, [0.01555444, 1.85629043, -1.36188064, -0.53595997, 0.02599574], atol=1e-05)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(round(q2_4, 5) == round(1.230297949608002, 5))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(q2_5, [[1.76405235, 0.40015721], [1.86755799, -0.97727788], [0.95008842, -0.15135721]], atol=1e-05)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(round(q2_6, 5) == round(1.8088688373462207, 5))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(round(q2_7, 5) == round(2.001256514017904, 5))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(q2_8, [0.0, 2.00125651, 1.38131852, 0.98321179, 1.86730039], atol=1e-05)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": [
      1,
      1,
      1,
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import math\n>>> math.isclose(q3_1, -0.07, abs_tol=0.01)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def checkq32(q3_2):\n...     tmp = {2017: 0.92, 2018: 0.85, 2019: 0.98}\n...     flag = True\n...     for i, v in q3_2.items():\n...         flag = flag & (round(v, 2) == round(tmp[i], 2))\n...     return flag\n>>> checkq32(q3_2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def checkq33(q3_3):\n...     tmp = {2017: 1.656, 2018: 1.53, 2019: 1.764}\n...     flag = True\n...     for i, v in q3_3.items():\n...         flag = flag & (round(v, 3) == round(tmp[i], 3))\n...     return flag\n>>> checkq33(q3_3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(round(q3_4, 5) == round(0.5923333333333335, 5))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q3_5 == 61)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q3_6 == 46)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def checkq37(q3_7):\n...     tmp = {2018: 0.85, 2015: 0.9, 2017: 0.92, 2019: 0.98, 2016: 1.01}\n...     flag = True\n...     for i, v in q3_7.items():\n...         flag = flag & (round(v, 2) == round(tmp[i], 2))\n...     return flag\n>>> checkq37(q3_7)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": [
      1,
      1,
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def checkq41(q4_1):\n...     tmp = {'Happiness': 6.9396, 'Log GDP per capita': 10.925769, 'Social support': 0.914219, 'Healthy life expectancy': 68.2995, 'Freedom to make life choices': 0.84262, 'Generosity': 0.149892, 'Perceptions of corruption': 0.699715}\n...     flag = True\n...     for i, v in q4_1.items():\n...         flag = flag & (round(v, 3) == round(tmp[i], 3))\n...     return flag\n>>> checkq41(q4_1)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> def checkq42(q4_2):\n...     tmp = {'Happiness': 6.0218, 'Log GDP per capita': 10.340017, 'Social support': 0.93473, 'Healthy life expectancy': 68.604958, 'Freedom to make life choices': 0.877709, 'Generosity': -0.111698, 'Perceptions of corruption': 0.623074}\n...     flag = True\n...     for i, v in q4_2.items():\n...         flag = flag & (round(v, 3) == round(tmp[i], 3))\n...     return flag\n>>> checkq42(q4_2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(round(q4_3, 5) == round(5.47323986284967, 5))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q4_4 == 53)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q4_5 == 57)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(q4_6 == 5)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
